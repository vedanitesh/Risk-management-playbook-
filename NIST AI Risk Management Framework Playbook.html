<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>NIST AI Risk Management Framework Playbook</title>
<style>
table {
  width: 100%;
  border-collapse: collapse;
}

table, th, td {
  border: 1px solid black;
  padding: 8px;
}

th {
  background-color: #f2f2f2;
}
</style>
</head>
<body>

<h2>NIST AI Risk Management Framework Playbook</h2>

<table>
  <tr>
    <th>Activity Group</th>
    <th>Activity</th>
    <th>Expected Evidence</th>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.1 Legal and regulatory requirements involving AI are understood, managed, and documented.</td>
    <td>
      <ol>
        <li>Documentation of relevant laws and regulations.</li>
        <li>Records of compliance measures, such as legal reviews and audits.</li>
        <li>Documentation demonstrating understanding and management of legal and regulatory requirements.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.2 The characteristics of trustworthy AI are integrated into organizational policies, processes, and procedures.</td>
    <td>
      <ol>
        <li>Documentation of policies reflecting trustworthy AI principles.</li>
        <li>Evidence of integration efforts, such as policy updates and training materials.</li>
        <li>Examples of trustworthy AI principles applied in decision-making processes.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.3 Processes and procedures are in place to determine the needed level of risk management activities based on the organization’s risk tolerance.</td>
    <td>
      <ol>
        <li>Documentation outlining risk tolerance levels.</li>
        <li>Procedures for assessing and determining risk management activities.</li>
        <li>Records of risk assessments and decisions based on risk tolerance.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.4 The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.</td>
    <td>
      <ol>
        <li>Transparent policies and procedures related to risk management.</li>
        <li>Evidence of risk management controls aligned with organizational priorities.</li>
        <li>Documentation of risk assessments, mitigation plans, and outcomes.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.5 Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, organizational roles and responsibilities are clearly defined, including determining the frequency of periodic review.</td>
    <td>
      <ol>
        <li>Monitoring plans and schedules.</li>
        <li>Clear roles and responsibilities for monitoring and review.</li>
        <li>Records of periodic reviews, evaluations, and adjustments to the risk management process.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.6 Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities.</td>
    <td>
      <ol>
        <li>Inventory of AI systems.</li>
        <li>Resource allocation plans based on risk priorities.</li>
        <li>Documentation of mechanisms for maintaining and updating the AI system inventory.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-1</td>
    <td>GOVERN 1.7 Processes and procedures are in place for decommissioning and phasing out of AI systems safely and in a manner that does not increase risks or decrease the organization’s trustworthiness.</td>
    <td>
      <ol>
        <li>Decommissioning procedures for AI systems.</li>
        <li>Evidence of safe decommissioning practices, such as data handling protocols.</li>
        <li>Records demonstrating adherence to decommissioning processes without compromising trustworthiness or increasing risks.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-2</td>
    <td>GOVERN 2.1 Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.</td>
    <td>
      <ol>
        <li>Documentation of roles, responsibilities, and communication lines.</li>
        <li>Training materials or documentation demonstrating clarity.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-2</td>
    <td>GOVERN 2.2 The organization’s personnel and partners receive AI risk management training to enable them to perform their duties and responsibilities consistent with related policies, procedures, and agreements.</td>
    <td>
      <ol>
        <li>Training records or documentation.</li>
        <li>Evidence of training programs aligned with policies and procedures.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-2</td>
    <td>GOVERN 2.3 Executive leadership of the organization takes responsibility for decisions about risks associated with AI system development and deployment.</td>
    <td>
      <ol>
        <li>Records demonstrating executive involvement in risk decisions.</li>
        <li>Documentation of executive responsibilities regarding AI risk.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-3</td>
    <td>GOVERN 3.1 Decision-makings related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a diverse team (e.g., diversity of demographics, disciplines, experience, expertise, and backgrounds).</td>
    <td>
      <ol>
        <li>Documentation showing diversity within decision-making teams.</li>
        <li>Records demonstrating diverse perspectives considered in risk management.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-3</td>
    <td>GOVERN 3.2 Policies and procedures are in place to define and differentiate roles and responsibilities for human-AI configurations and oversight of AI systems.</td>
    <td>
      <ol>
        <li>Documentation of policies and procedures related to human-AI configurations and oversight.</li>
        <li>Evidence of role definitions and responsibilities.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-4</td>
    <td>GOVERN 4.1 Organizational policies, and practices are in place to foster a critical thinking and safety-first mindset in the design, development, deployment, and uses of AI systems to minimize negative impacts.</td>
    <td>
      <ol>
        <li>Documentation of policies promoting critical thinking and safety-first mindset.</li>
        <li>Examples of practices reflecting these policies.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-4</td>
    <td>GOVERN 4.2 Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate and use, and communicate about the impacts more broadly.</td>
    <td>
      <ol>
        <li>Records of risk documentation.</li>
        <li>Evidence of communication about AI risks and impacts.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-4</td>
    <td>GOVERN 4.3 Organizational practices are in place to enable AI testing, identification of incidents, and information sharing.</td>
    <td>
      <ol>
        <li>Documentation of testing procedures and incident identification mechanisms.</li>
        <li>Records of information sharing practices related to AI incidents.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-5</td>
    <td>GOVERN 5.1 Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.</td>
    <td>
      <ol>
        <li>Documentation of feedback collection and integration processes.</li>
        <li>Records of feedback received and actions taken.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-5</td>
    <td>GOVERN 5.2 Mechanisms are established to enable AI actors to regularly incorporate adjudicated feedback from relevant AI actors into system design and implementation.</td>
    <td>
      <ol>
        <li>Documentation of mechanisms for incorporating feedback.</li>
        <li>Evidence of feedback incorporation into system design and implementation.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-6</td>
    <td>GOVERN 6.1 Policies and procedures are in place to address AI risks associated with third-party entities, including risks of infringement of a third party’s intellectual property or other rights.</td>
    <td>
      <ol>
        <li>Documentation of policies and procedures related to third-party AI risks.</li>
        <li>Evidence of risk assessments and mitigation strategies for third-party risks.</li>
      </ol>
    </td>
  </tr>
  <tr>
    <td>GOVERN-6</td>
    <td>GOVERN 6.2 Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.</td>
    <td>
      <ol>
        <li>Documentation of contingency processes for third-party failures or incidents.</li>
        <li>Records of incident responses and resolutions.</li>
      </ol>
    </td>
  </tr>
</table>

</body>
</html>
